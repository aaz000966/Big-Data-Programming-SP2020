{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "from pyspark import *\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import *\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import col, lit, when\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to inite new spark session instance\n",
    "spark = SparkSession.builder.appName(\"graphProcessing\").config(\"spark.master\", \"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- dockcount: integer (nullable = true)\n",
      " |-- landmark: string (nullable = true)\n",
      " |-- installation: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- Trip ID: integer (nullable = true)\n",
      " |-- Duration: integer (nullable = true)\n",
      " |-- Start Date: string (nullable = true)\n",
      " |-- Start Station: string (nullable = true)\n",
      " |-- Start Terminal: integer (nullable = true)\n",
      " |-- End Date: string (nullable = true)\n",
      " |-- End Station: string (nullable = true)\n",
      " |-- End Terminal: integer (nullable = true)\n",
      " |-- Bike #: integer (nullable = true)\n",
      " |-- Subscriber Type: string (nullable = true)\n",
      " |-- Zip Code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Part(1)(1): To import the dataset as a csv file and create data frames directly on import \n",
    "\n",
    "station_data_RDD = spark.read.csv(\"input/201508_station_data.csv\", header=True, inferSchema=True)\n",
    "trip_data_RDD = spark.read.csv(\"input/201508_trip_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "#To Print RDDs Schema:\n",
    "station_data_RDD.printSchema()\n",
    "trip_data_RDD.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------+-----------+---------+--------+------------+\n",
      "|station_id|                name|      lat|       long|dockcount|landmark|installation|\n",
      "+----------+--------------------+---------+-----------+---------+--------+------------+\n",
      "|         2|San Jose Diridon ...|37.329732|-121.901782|       27|San Jose|    8/6/2013|\n",
      "|         3|San Jose Civic Ce...|37.330698|-121.888979|       15|San Jose|    8/5/2013|\n",
      "|         4|Santa Clara at Al...|37.333988|-121.894902|       11|San Jose|    8/6/2013|\n",
      "|         5|    Adobe on Almaden|37.331415|  -121.8932|       19|San Jose|    8/5/2013|\n",
      "|         6|    San Pedro Square|37.336721|-121.894074|       15|San Jose|    8/7/2013|\n",
      "+----------+--------------------+---------+-----------+---------+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To show first 5 records of each RDD\n",
    "station_data_RDD.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------------+--------------------+--------------+---------------+--------------------+------------+------+---------------+--------+\n",
      "|Trip ID|Duration|     Start Date|       Start Station|Start Terminal|       End Date|         End Station|End Terminal|Bike #|Subscriber Type|Zip Code|\n",
      "+-------+--------+---------------+--------------------+--------------+---------------+--------------------+------------+------+---------------+--------+\n",
      "| 913460|     765|8/31/2015 23:26|Harry Bridges Pla...|            50|8/31/2015 23:39|San Francisco Cal...|          70|   288|     Subscriber|    2139|\n",
      "| 913459|    1036|8/31/2015 23:11|San Antonio Shopp...|            31|8/31/2015 23:28|Mountain View Cit...|          27|    35|     Subscriber|   95032|\n",
      "| 913455|     307|8/31/2015 23:13|      Post at Kearny|            47|8/31/2015 23:18|   2nd at South Park|          64|   468|     Subscriber|   94107|\n",
      "| 913454|     409|8/31/2015 23:10|  San Jose City Hall|            10|8/31/2015 23:17| San Salvador at 1st|           8|    68|     Subscriber|   95113|\n",
      "| 913453|     789|8/31/2015 23:09|Embarcadero at Fo...|            51|8/31/2015 23:22|Embarcadero at Sa...|          60|   487|       Customer|    9069|\n",
      "+-------+--------+---------------+--------------------+--------------+---------------+--------------------+------------+------+---------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To show first 5 records of each RDD\n",
    "trip_data_RDD.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 70 rows before removing duplicates, and 70 rows after removing duplicates\n",
      "There were 51927 rows before removing duplicates, and 51927 rows after removing duplicates\n"
     ]
    }
   ],
   "source": [
    "#Part(1)(3): Remove duplicates\n",
    "# Remove duplicate entries from stations RDD\n",
    "station_data_RDD_NoDUP = station_data_RDD.dropDuplicates()\n",
    "\n",
    "# Count the number of rows\n",
    "print(\"There were {} rows before removing duplicates, and {} rows after removing duplicates\".format(station_data_RDD.count(), station_data_RDD_NoDUP.count()))\n",
    "\n",
    "\n",
    "# Remove duplicate entries from trips RDD\n",
    "trip_data_RDD_NoDUP = trip_data_RDD.dropDuplicates()\n",
    "\n",
    "# Count the number of rows\n",
    "print(\"There were {} rows before removing duplicates, and {} rows after removing duplicates\".format(trip_data_RDD.count(), trip_data_RDD_NoDUP.count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part(1)(4):Name Columns\n",
    "station_data_RDD = station_data_RDD.withColumnRenamed(\"station_id\", \"id\")\n",
    "trip_data_RDD = trip_data_RDD.withColumnRenamed(\"Start Terminal\", \"src\")\n",
    "trip_data_RDD = trip_data_RDD.withColumnRenamed(\"End Terminal\", \"dst\")\n",
    "trip_data_RDD = trip_data_RDD.withColumnRenamed(\"Trip ID\", \"trip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------+-----------+---------+--------+------------+\n",
      "| id|                name|      lat|       long|dockcount|landmark|installation|\n",
      "+---+--------------------+---------+-----------+---------+--------+------------+\n",
      "|  2|San Jose Diridon ...|37.329732|-121.901782|       27|San Jose|    8/6/2013|\n",
      "|  3|San Jose Civic Ce...|37.330698|-121.888979|       15|San Jose|    8/5/2013|\n",
      "|  4|Santa Clara at Al...|37.333988|-121.894902|       11|San Jose|    8/6/2013|\n",
      "|  5|    Adobe on Almaden|37.331415|  -121.8932|       19|San Jose|    8/5/2013|\n",
      "|  6|    San Pedro Square|37.336721|-121.894074|       15|San Jose|    8/7/2013|\n",
      "+---+--------------------+---------+-----------+---------+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+--------+---------------+--------------------+---+---------------+--------------------+---+------+---------------+--------+\n",
      "|  trip|Duration|     Start Date|       Start Station|src|       End Date|         End Station|dst|Bike #|Subscriber Type|Zip Code|\n",
      "+------+--------+---------------+--------------------+---+---------------+--------------------+---+------+---------------+--------+\n",
      "|913460|     765|8/31/2015 23:26|Harry Bridges Pla...| 50|8/31/2015 23:39|San Francisco Cal...| 70|   288|     Subscriber|    2139|\n",
      "|913459|    1036|8/31/2015 23:11|San Antonio Shopp...| 31|8/31/2015 23:28|Mountain View Cit...| 27|    35|     Subscriber|   95032|\n",
      "|913455|     307|8/31/2015 23:13|      Post at Kearny| 47|8/31/2015 23:18|   2nd at South Park| 64|   468|     Subscriber|   94107|\n",
      "|913454|     409|8/31/2015 23:10|  San Jose City Hall| 10|8/31/2015 23:17| San Salvador at 1st|  8|    68|     Subscriber|   95113|\n",
      "|913453|     789|8/31/2015 23:09|Embarcadero at Fo...| 51|8/31/2015 23:22|Embarcadero at Sa...| 60|   487|       Customer|    9069|\n",
      "+------+--------+---------------+--------------------+---+---------------+--------------------+---+------+---------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Part(1)(5): Output Data Frame\n",
    "station_data_RDD.show(5)\n",
    "trip_data_RDD.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|                name|\n",
      "+---+--------------------+\n",
      "|  2|San Jose Diridon ...|\n",
      "|  3|San Jose Civic Ce...|\n",
      "|  4|Santa Clara at Al...|\n",
      "|  5|    Adobe on Almaden|\n",
      "|  6|    San Pedro Square|\n",
      "+---+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---+---+------+\n",
      "|src|dst|  trip|\n",
      "+---+---+------+\n",
      "| 50| 70|913460|\n",
      "| 31| 27|913459|\n",
      "| 47| 64|913455|\n",
      "| 10|  8|913454|\n",
      "| 51| 60|913453|\n",
      "+---+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Part(1)(6):Create vertices\n",
    "#To create temporary view of RDDs\n",
    "station_data_RDD.createOrReplaceTempView(\"stations\")\n",
    "trip_data_RDD.createOrReplaceTempView(\"trips\")\n",
    "vertices = spark.sql(\"SELECT id, name FROM stations\")\n",
    "edges = spark.sql(\"SELECT src, dst, trip FROM trips\")\n",
    "vertices.show(5)\n",
    "edges.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o196.createGraph.\n: java.lang.NoSuchMethodError: scala.Predef$.refArrayOps([Ljava/lang/Object;)Lscala/collection/mutable/ArrayOps;\n\tat org.graphframes.GraphFrame$.apply(GraphFrame.scala:609)\n\tat org.graphframes.GraphFramePythonAPI.createGraph(GraphFramePythonAPI.scala:10)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-24-338b8f34183b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mgraph\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mGraphFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvertices\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0medges\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/spark-ce02c922-55f6-4980-a977-a5763ae20521/userFiles-20edecd0-034c-4afd-8cc3-136dab098990/graphframes_graphframes-0.5.0-spark2.1-s_2.11.jar/graphframes/graphframe.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, v, e)\u001B[0m\n\u001B[1;32m     85\u001B[0m                 .format(self.DST, \",\".join(e.columns)))\n\u001B[1;32m     86\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 87\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jvm_graph\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jvm_gf_api\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreateGraph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     88\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     89\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pyconda/lib/python3.6/site-packages/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1255\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1256\u001B[0m         return_value = get_return_value(\n\u001B[0;32m-> 1257\u001B[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[0m\u001B[1;32m   1258\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1259\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mtemp_arg\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtemp_args\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Downloads/spark-3.0.0-preview2-bin-hadoop2.7/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m     96\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     97\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 98\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     99\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pyconda/lib/python3.6/site-packages/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    326\u001B[0m                 raise Py4JJavaError(\n\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 328\u001B[0;31m                     format(target_id, \".\", name), value)\n\u001B[0m\u001B[1;32m    329\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    330\u001B[0m                 raise Py4JError(\n",
      "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o196.createGraph.\n: java.lang.NoSuchMethodError: scala.Predef$.refArrayOps([Ljava/lang/Object;)Lscala/collection/mutable/ArrayOps;\n\tat org.graphframes.GraphFrame$.apply(GraphFrame.scala:609)\n\tat org.graphframes.GraphFramePythonAPI.createGraph(GraphFramePythonAPI.scala:10)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "graph = GraphFrame(vertices, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part(1)(7):Show some vertices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part(1)(8):Show some edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part(1)(9):Vertex in-Degree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part(1)(10):Vertex out-Degree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part(1)(11):Apply the motif findings.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('pyconda': conda)",
   "language": "python",
   "name": "python361064bitpycondacondabe5a39644e52403d882c62f3ed73be6a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}